package org.cstaylor.antlr4.utils;

import java.io.BufferedInputStream;
import java.io.FileInputStream;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.io.Reader;
import java.lang.reflect.Constructor;
import java.lang.reflect.Method;
import java.nio.charset.Charset;
import java.nio.charset.UnsupportedCharsetException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.util.ArrayList;
import java.util.Collection;

import org.antlr.v4.runtime.ANTLRInputStream;
import org.antlr.v4.runtime.CharStream;
import org.antlr.v4.runtime.CommonTokenStream;
import org.antlr.v4.runtime.DiagnosticErrorListener;
import org.antlr.v4.runtime.Lexer;
import org.antlr.v4.runtime.Parser;
import org.antlr.v4.runtime.ParserRuleContext;
import org.antlr.v4.runtime.TokenStream;
import org.antlr.v4.runtime.atn.PredictionMode;
import org.antlr.v4.runtime.misc.Pair;

/**
 * Instead of using grun, I wanted something I could call from test code, which means I wanted to dump the command-line arguments
 * and use this in a fluent manner.
 * 
 * Note: the use of the Path API makes this Java 7+ only.
 * 
 * @author cstaylor
 */
public class ProgrammaticTestRig
{
    /**
     * The class derived from the grammar rules that will tokenize the incoming stream of characters. Required.
     */
    private Class<? extends Lexer> lexerClass;
    
    /**
     * The class derived from the grammar rules that will parse the incoming stream of tokens.  Only needed
     * if parsing is wanted.
     */
    private Class<? extends Parser> parserClass;

    /**
     * Display a pretty Swing GUI of our successful parse output?
     */
    private boolean gui;
    
    /**
     * Send a LISPy string to standard out of the AST?
     */
    private boolean tree;
    
    /**
     * Enable trace logging in the Parser?
     */
    private boolean trace;
    
    /**
     * Changes the default prediction mode to SLL
     */
    private boolean sll;
    
    /**
     * Captures and displays errors and changes the default prediction mode to capture ambiguous items
     */
    private boolean diagnostics;
    
    /**
     * What encoding format is the token stream?  This encoding is used for all input streams
     */
    private Charset encoding;
    
    /**
     * Ignore the value of parserClass and stop after tokenizing the input streams
     */
    private boolean lexOnly;
    
    /**
     * If not-null, walk all of the found tokens during lexing and send them to this callback.  Optional.
     */
    private TokenFoundCallback tokenCallback;
    
    /**
     * The character streams containing the tokens we want to parse.  At least one is required
     */
    private Collection<Pair<InputStream,InputStreamReader>> inputFiles;
    
    /**
     * If parsing, from which rule do we want to start interpreting the tokens?  Required 
     */
    private String startRuleName;
        
    public ProgrammaticTestRig ( )
    {
        this.inputFiles = new ArrayList<Pair<InputStream,InputStreamReader>>();
    }
    
    /**
     * Fluent method for adding input files to our list of input streams.
     * @param inputPaths the array of paths that we want to read during processing
     * @return a self-reference for method chaining
     * @throws IOException if we have trouble opening the streams
     */
    public ProgrammaticTestRig INPUT ( Path... inputPaths ) throws IOException
    {
        for ( Path p : inputPaths ) 
        {
            if ( Files.exists( p ) )
            {
                BufferedInputStream bis = new BufferedInputStream ( new FileInputStream ( p.toFile() ) );
                InputStreamReader reader = ( encoding == null ) ? new InputStreamReader( bis ) : new InputStreamReader ( bis, encoding );
                Pair<InputStream,InputStreamReader> pair = new Pair<InputStream,InputStreamReader>(bis,reader);
                this.inputFiles.add ( pair );
            }
        }
        return this;
    }
    
    /**
     * Fluent method for setting the starting rule during parsing.  Must be non-null.
     * @param parserStartRule the name of the rule we'll start with during processing
     * @return a self-reference for method chaining 
     */
    public ProgrammaticTestRig START_RULE ( String parserStartRule )
    {
        if ( parserStartRule == null ) throw new IllegalArgumentException ( "parserStartRule can't be null" );
        this.startRuleName = parserStartRule;
        return this;
    }
    
    /**
     * Bypass the parsing phase.  Useful for checking the token rules.
     * @return a self-reference for method chaining
     */
    public ProgrammaticTestRig LEXONLY ( )
    {
        this.lexOnly = true;
        return this;
    }
    
    /**
     * The Parser subclass generated by antlr for interpreting our token streams.  Required if parsing is enabled.
     * @param klass the Antlr parser subclass that will interpret the tokens during processing
     * @return a self-reference for method chaining
     */
    public ProgrammaticTestRig PARSER ( Class<? extends Parser> klass )
    {
        if ( klass == null ) throw new IllegalArgumentException ( "parser can't be null" );
        this.parserClass = klass;
        return this;
    }
    
    /**
     * The Lexer subclass generated by antlr for generating token streams.  Required.
     * @param klass the Antlr parser subclass that will generate tokens during processing
     * @return a self-reference for method chaining
     */
    public ProgrammaticTestRig LEXER ( Class<? extends Lexer> klass )
    {
        if ( klass == null ) throw new IllegalArgumentException ( "lexer can't be null" );
        this.lexerClass = klass;
        return this;
    }
    
    /**
     * Display a LISPy tree to stdout during processing.
     * @return a self-reference for method chaining
     */
    public ProgrammaticTestRig TREE ( )
    {
        this.tree = true;
        return this;
    }
   
    /**
     * Don't display a LISPy tree to stdout during processing.
     * @return a self-reference for method chaining
     */
    public ProgrammaticTestRig NOTREE ( )
    {
        this.tree = false;
        return this;
    }
    
    /**
     * Create a Swing UI showing the AST after parsing.
     * @return a self-reference for method chaining
     */
    public ProgrammaticTestRig GUI ( )
    {
        this.gui = true;
        return this;
    }

    /**
     * Don't create a Swing UI showing the AST after parsing.
     * @return a self-reference for method chaining
     */
    public ProgrammaticTestRig NOGUI ( )
    {
        this.gui = false;
        return this;
    }
    
    /**
     * During lexing, enumerate the tokens and send them to this callback object.
     * @param tokenCallback will receive all of the discovered tokens, one at a time
     * @return a self-reference for method chaining
     */
    public ProgrammaticTestRig TOKENS ( TokenFoundCallback tokenCallback )
    {
        if ( tokenCallback == null ) throw new IllegalArgumentException ( "tokenCallback can't be null" );
        this.tokenCallback = tokenCallback;
        return this;
    }

    /**
     * During lexing, don't enumerate the tokens for debugging purposes.
     * @return a self-reference for method chaining
     */
    public ProgrammaticTestRig NOTOKENS ( )
    {
        this.tokenCallback = null;
        return this;
    }

    /**
     * Enable additional trace logging during parsing.
     * @return a self-reference for method chaining
     */
    public ProgrammaticTestRig TRACE ( )
    {
        this.trace = true;
        return this;
    }

    /**
     * Disable additional trace logging during parsing.
     * @return a self-reference for method chaining
     */
    public ProgrammaticTestRig NOTRACE ( )
    {
        this.trace = false;
        return this;
    }
    
    /**
     * Enable SSL interpretation mode during parsing.
     * @return a self-reference for method chaining
     */
    public ProgrammaticTestRig SLL ( )
    {
        this.sll = true;
        return this;
    }

    /**
     * Resets the interpretation mode back to the default.
     * @return a self-reference for method chaining
     */
    public ProgrammaticTestRig NOSLL ( )
    {
        this.sll = false;
        return this;
    }
    
    /**
     * Enable stricter interpretation modes and display all errors to stdout.
     * @return a self-reference for method chaining
     */
    public ProgrammaticTestRig DIAGNOSTICS ( )
    {
        this.diagnostics = true;
        return this;
    }
    
    /**
     * Resets the interpretation mode back to the default and ignores errors.
     * @return a self-reference for method chaining
     */
    public ProgrammaticTestRig NODIAGNOSTICS ( )
    {
        this.diagnostics = false;
        return this;
    }

    /**
     * What character encoding should I use when interpreting the input streams. If a non-ASCII encoding is used, this must be
     * callbed before INPUT.
     * @param enc the name of the character encoding
     * @return a self-reference for method chaining
     */
    public ProgrammaticTestRig ENCODING ( String enc )
    {
        if ( enc == null ) throw new IllegalArgumentException ( "encoding can't be null" );
        try
        {
            this.encoding = Charset.forName(enc);
        }
        catch ( UnsupportedCharsetException oops )
        {
            throw new IllegalArgumentException ( String.format ( "%s isn't a valid encoding", enc ), oops );
        }
        return this;
    }
    
    //
    // Creates a lexer based on the lexerClass
    //
    private Lexer createLexer ( ) throws Exception
    {
        if ( lexerClass == null ) throw new IllegalStateException ( "lexer can't be null" );
        Constructor<? extends Lexer> lexerCtor = lexerClass.getConstructor(CharStream.class);
        Lexer lexer = lexerCtor.newInstance((CharStream)null);
        return lexer;
    }
    
    //
    // If parsing is enabled, and we have a valid parserClass, create that parser and enable the various settings previously
    // set through the fluent api.
    //
    // This code is lifted directly from the Antlr testrig class
    //
    private Parser createParser ( ) throws Exception
    {
        if ( lexOnly ) return null;
        if ( parserClass == null ) throw new IllegalStateException ( "parser can't be null" );
        Constructor<? extends Parser> parserCtor = parserClass.getConstructor(TokenStream.class);
        Parser parser = parserCtor.newInstance((TokenStream)null); 
        if ( diagnostics ) {
            parser.addErrorListener(new DiagnosticErrorListener());
            parser.getInterpreter().setPredictionMode(PredictionMode.LL_EXACT_AMBIG_DETECTION);
        }
        if ( tree || gui ) {
            parser.setBuildParseTree(true);
        }
        if ( sll ) { // overrides diagnostics
            parser.getInterpreter().setPredictionMode(PredictionMode.SLL);
        }
        parser.setTrace(trace);
        return parser;
    }
    
    //
    // Parse the token stream and optionally display it to stdout as a LISPy tree and/or a AST diagram in a window
    //
    protected void parse ( Parser parser, Method startRule, CommonTokenStream stream ) throws Exception
    {
        parser.setTokenStream(stream);
        ParserRuleContext treeObj = (ParserRuleContext)startRule.invoke(parser, (Object[])null);
        if ( tree ) {
            System.out.println(treeObj.toStringTree(parser));
        }
        if ( gui ) {
            treeObj.inspect(parser);
        }
    }
    
    //
    // Convert the stream of characters into a stream of Tokens for optional parsing
    //
    protected CommonTokenStream lex ( Lexer lexer, Reader reader ) throws IOException
    {
        ANTLRInputStream input = new ANTLRInputStream(reader);
        lexer.setInputStream(input);
        CommonTokenStream tokens = new CommonTokenStream(lexer);
        tokens.fill();
        if ( tokenCallback != null ) 
        {
            for ( Object tok : tokens.getTokens() ) tokenCallback.token(this, tok);
        }
        return tokens;
    }
    
    /**
     * The main entry point after all of the various settings are enabled through the fluent API.
     * @throws Exception if some of our settings are missing or conflicting or if we can't instantiate the lexer and parser classes
     */
    public void process() throws Exception 
    {
        try
        {
            Lexer lexer = createLexer ( );
            Parser parser = createParser ( );
            Method method = parser == null || startRuleName == null ? null : parser.getClass().getMethod ( startRuleName );
            
            if ( method == null ) 
            {
                for ( Pair<InputStream,InputStreamReader> p : inputFiles ) lex ( lexer, p.b );
            } 
            else {
                for ( Pair<InputStream,InputStreamReader> p : inputFiles ) parse ( parser, method, lex ( lexer, p.b ) );
            }
        }
        finally
        {
            for ( Pair<InputStream,InputStreamReader> p : inputFiles ) 
            {
                try { p.b.close(); } catch ( IOException oops ) { /* do nothing */ }
                try { p.a.close(); } catch ( IOException oops ) { /* do nothing */ }
            }
        }
    }
    
    /**
     * Implement this interface and pass an instance to the TOKENS fluent api to receive callbacks for each token during lexing.
     */
    public interface TokenFoundCallback
    {
        public void token ( ProgrammaticTestRig source, Object token );
    }
}